name: CI/CD Pipeline - House Prices Prediction

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, "3.10"]

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov flake8 black isort
        pip install -r requirements.txt

    - name: Lint with flake8
      run: |
        # stop the build if there are Python syntax errors or undefined names
        flake8 src/ --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
        flake8 src/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: Check code formatting with black
      run: |
        black --check src/ tests/

    - name: Check import sorting with isort
      run: |
        isort --check-only src/ tests/

    - name: Test with pytest
      run: |
        pytest tests/ -v --cov=src --cov-report=xml --cov-report=html --cov-report=term

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        token: ${{ secrets.CODECOV_TOKEN }}
        flags: unittests
        name: codecov-umbrella

  build:
    needs: test
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.9
      uses: actions/setup-python@v5
      with:
        python-version: 3.9

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Build package
      run: |
        python setup.py sdist bdist_wheel

    - name: Test model training
      run: |
        python3 -c "
        import pandas as pd
        from sklearn.linear_model import BayesianRidge
        from sklearn.pipeline import Pipeline
        from sklearn.preprocessing import StandardScaler
        import numpy as np
        
        # Test simple d'entraînement avec BayesianRidge
        X = pd.DataFrame({'Feature1': [1, 2, 3, 4, 5]})
        y = pd.Series([100000, 200000, 300000, 400000, 500000])
        y_log = np.log1p(y)
        
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('model', BayesianRidge())
        ])
        pipeline.fit(X, y_log)
        
        score = pipeline.score(X, y_log)
        print(f'Model R² score: {score}')
        assert score > 0.9
        "


  deploy-staging:
    needs: [test, build]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment: staging

    steps:
    - uses: actions/checkout@v4

    - name: Deploy to staging
      run: |
        echo "Déploiement sur l'environnement de staging"
        # Ajouter ici les commandes de déploiement staging

  deploy-production:
    needs: [test, build]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    environment: production

    steps:
    - uses: actions/checkout@v4

    - name: Deploy to production
      run: |
        echo "Déploiement sur l'environnement de production"
        # Ajouter ici les commandes de déploiement production

  mlflow-tracking:
    needs: test
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.9
      uses: actions/setup-python@v5
      with:
        python-version: 3.9

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install mlflow
        pip install -r requirements.txt

    - name: Run MLflow experiment
      run: |
        # Lancer un experiment MLflow avec le nouveau pipeline
        python3 -c "
        import mlflow
        import mlflow.sklearn
        from sklearn.linear_model import BayesianRidge
        from sklearn.pipeline import Pipeline
        from sklearn.preprocessing import StandardScaler
        from sklearn.metrics import mean_squared_error, r2_score
        import numpy as np
        import pandas as pd
        
        mlflow.set_experiment('House Prices CI Experiment')
        
        with mlflow.start_run():
            # Données de test
            X = pd.DataFrame(np.random.rand(100, 5), columns=[f'Feature{i}' for i in range(5)])
            y = 100000 + 50000 * X['Feature0'].values + np.random.randn(100) * 5000
            y_log = np.log1p(y)
            
            # Pipeline avec BayesianRidge
            pipeline = Pipeline([
                ('scaler', StandardScaler()),
                ('model', BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06))
            ])
            pipeline.fit(X, y_log)
            
            # Métriques
            y_pred_log = pipeline.predict(X)
            y_pred = np.expm1(y_pred_log)
            rmse = np.sqrt(mean_squared_error(y, y_pred))
            r2 = r2_score(y, y_pred)
            
            # Logging MLflow
            mlflow.log_param('model_type', 'BayesianRidge')
            mlflow.log_param('alpha_1', 1e-06)
            mlflow.log_param('alpha_2', 1e-06)
            mlflow.log_param('use_log_transform', True)
            mlflow.log_metric('rmse', rmse)
            mlflow.log_metric('r2_score', r2)
            mlflow.sklearn.log_model(pipeline, 'model')
            
            print(f'MLflow experiment logged - RMSE: {rmse}, R²: {r2}')
        "

    - name: Upload MLflow artifacts
      uses: actions/upload-artifact@v4
      with:
        name: mlflow-artifacts
        path: mlruns/
        retention-days: 30